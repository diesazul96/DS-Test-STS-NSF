{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Text Similarity Clustering\n",
    "\n",
    "Before startint to code the solution, I check for some documents from de dataset to get familiar with the format of the documents and to analice what information I should take from there since not every field was usefull.\n",
    "\n",
    "After that quick analysis I decided to use information about the university and it's location and also the title and abstract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used two spacy models, the bigger one **en_core_web_trf** for a better lemmatization and **en_core_web_lg** to get the word vectors of the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:03:53.116895Z",
     "start_time": "2021-10-11T02:03:50.147756Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_trf', disable=['tagger', 'parser', 'ner'])\n",
    "nlp.add_pipe('sentencizer')\n",
    "en_stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading files from XML format to pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:03:53.206895Z",
     "start_time": "2021-10-11T02:03:53.118895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13154\n"
     ]
    }
   ],
   "source": [
    "path = './2020/'\n",
    "files = os.listdir(path)\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:05:35.548764Z",
     "start_time": "2021-10-11T02:03:53.208893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>division</th>\n",
       "      <th>university</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000005</td>\n",
       "      <td>Collaborative Research: Excellence in Research...</td>\n",
       "      <td>07/01/2020</td>\n",
       "      <td>Direct For Biological Sciences</td>\n",
       "      <td>Division Of Integrative Organismal Systems</td>\n",
       "      <td>Howard University</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>Head and heart development are closely intertw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000009</td>\n",
       "      <td>Workshop on Replication of a Community-Engaged...</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>Direct For Education and Human Resources</td>\n",
       "      <td>Division Of Undergraduate Education</td>\n",
       "      <td>University of Notre Dame</td>\n",
       "      <td>NOTRE DAME</td>\n",
       "      <td>United States</td>\n",
       "      <td>The National Academy of Engineering identified...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000012</td>\n",
       "      <td>Brazos Analysis Seminar</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>Direct For Mathematical &amp; Physical Scien</td>\n",
       "      <td>Division Of Mathematical Sciences</td>\n",
       "      <td>Baylor University</td>\n",
       "      <td>Waco</td>\n",
       "      <td>United States</td>\n",
       "      <td>This award provides three years of funding to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000021</td>\n",
       "      <td>Collaborative Research: ECR EIE DCL: The Devel...</td>\n",
       "      <td>09/01/2020</td>\n",
       "      <td>Direct For Education and Human Resources</td>\n",
       "      <td>Division Of Human Resource Development</td>\n",
       "      <td>Michigan State University</td>\n",
       "      <td>East Lansing</td>\n",
       "      <td>United States</td>\n",
       "      <td>This collaborative research project, involving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000028</td>\n",
       "      <td>Research Initiation Award: Microwave Synthesis...</td>\n",
       "      <td>05/01/2020</td>\n",
       "      <td>Direct For Education and Human Resources</td>\n",
       "      <td>Division Of Human Resource Development</td>\n",
       "      <td>Bowie State University</td>\n",
       "      <td>BOWIE</td>\n",
       "      <td>United States</td>\n",
       "      <td>Research Initiation Awards provide support for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>2055767</td>\n",
       "      <td>National Center for Next Generation Manufacturing</td>\n",
       "      <td>07/01/2021</td>\n",
       "      <td>Direct For Education and Human Resources</td>\n",
       "      <td>Division Of Undergraduate Education</td>\n",
       "      <td>Tunxis Community-Technical College</td>\n",
       "      <td>Farmington</td>\n",
       "      <td>United States</td>\n",
       "      <td>Recent studies have highlighted the nation's i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>2055771</td>\n",
       "      <td>NSF-BSF: Dynamics and Operator Algebras beyond...</td>\n",
       "      <td>08/01/2021</td>\n",
       "      <td>Direct For Mathematical &amp; Physical Scien</td>\n",
       "      <td>Division Of Mathematical Sciences</td>\n",
       "      <td>University of Oregon Eugene</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>United States</td>\n",
       "      <td>This project links two mathematical fields, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>2055772</td>\n",
       "      <td>Collaborative Research: SaTC: CORE: Medium: Na...</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>Direct For Computer &amp; Info Scie &amp; Enginr</td>\n",
       "      <td>Division Of Computer and Network Systems</td>\n",
       "      <td>International Computer Science Institute</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>United States</td>\n",
       "      <td>Recent years have seen a dramatic rise in mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>2055773</td>\n",
       "      <td>Collaborative Research: SaTC: CORE: Medium: Na...</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>Direct For Computer &amp; Info Scie &amp; Enginr</td>\n",
       "      <td>Division Of Computer and Network Systems</td>\n",
       "      <td>St Mary's University San Antonio</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>United States</td>\n",
       "      <td>Recent years have seen a dramatic rise in mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13153</th>\n",
       "      <td>2055781</td>\n",
       "      <td>Increasing the Cloud System Administration Ser...</td>\n",
       "      <td>07/01/2021</td>\n",
       "      <td>Direct For Education and Human Resources</td>\n",
       "      <td>Division Of Undergraduate Education</td>\n",
       "      <td>College of Southern Nevada</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>United States</td>\n",
       "      <td>The Information Technology (IT) workforce is c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13154 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title        date  \\\n",
       "0      2000005  Collaborative Research: Excellence in Research...  07/01/2020   \n",
       "1      2000009  Workshop on Replication of a Community-Engaged...  01/01/2020   \n",
       "2      2000012                            Brazos Analysis Seminar  02/01/2020   \n",
       "3      2000021  Collaborative Research: ECR EIE DCL: The Devel...  09/01/2020   \n",
       "4      2000028  Research Initiation Award: Microwave Synthesis...  05/01/2020   \n",
       "...        ...                                                ...         ...   \n",
       "13149  2055767  National Center for Next Generation Manufacturing  07/01/2021   \n",
       "13150  2055771  NSF-BSF: Dynamics and Operator Algebras beyond...  08/01/2021   \n",
       "13151  2055772  Collaborative Research: SaTC: CORE: Medium: Na...  03/01/2021   \n",
       "13152  2055773  Collaborative Research: SaTC: CORE: Medium: Na...  03/01/2021   \n",
       "13153  2055781  Increasing the Cloud System Administration Ser...  07/01/2021   \n",
       "\n",
       "                                           area  \\\n",
       "0                Direct For Biological Sciences   \n",
       "1      Direct For Education and Human Resources   \n",
       "2      Direct For Mathematical & Physical Scien   \n",
       "3      Direct For Education and Human Resources   \n",
       "4      Direct For Education and Human Resources   \n",
       "...                                         ...   \n",
       "13149  Direct For Education and Human Resources   \n",
       "13150  Direct For Mathematical & Physical Scien   \n",
       "13151  Direct For Computer & Info Scie & Enginr   \n",
       "13152  Direct For Computer & Info Scie & Enginr   \n",
       "13153  Direct For Education and Human Resources   \n",
       "\n",
       "                                         division  \\\n",
       "0      Division Of Integrative Organismal Systems   \n",
       "1             Division Of Undergraduate Education   \n",
       "2               Division Of Mathematical Sciences   \n",
       "3          Division Of Human Resource Development   \n",
       "4          Division Of Human Resource Development   \n",
       "...                                           ...   \n",
       "13149         Division Of Undergraduate Education   \n",
       "13150           Division Of Mathematical Sciences   \n",
       "13151    Division Of Computer and Network Systems   \n",
       "13152    Division Of Computer and Network Systems   \n",
       "13153         Division Of Undergraduate Education   \n",
       "\n",
       "                                     university          city        country  \\\n",
       "0                             Howard University    Washington  United States   \n",
       "1                      University of Notre Dame    NOTRE DAME  United States   \n",
       "2                             Baylor University          Waco  United States   \n",
       "3                     Michigan State University  East Lansing  United States   \n",
       "4                        Bowie State University         BOWIE  United States   \n",
       "...                                         ...           ...            ...   \n",
       "13149        Tunxis Community-Technical College    Farmington  United States   \n",
       "13150               University of Oregon Eugene        Eugene  United States   \n",
       "13151  International Computer Science Institute      Berkeley  United States   \n",
       "13152          St Mary's University San Antonio   San Antonio  United States   \n",
       "13153                College of Southern Nevada     Las Vegas  United States   \n",
       "\n",
       "                                                abstract  \n",
       "0      Head and heart development are closely intertw...  \n",
       "1      The National Academy of Engineering identified...  \n",
       "2      This award provides three years of funding to ...  \n",
       "3      This collaborative research project, involving...  \n",
       "4      Research Initiation Awards provide support for...  \n",
       "...                                                  ...  \n",
       "13149  Recent studies have highlighted the nation's i...  \n",
       "13150  This project links two mathematical fields, dy...  \n",
       "13151  Recent years have seen a dramatic rise in mobi...  \n",
       "13152  Recent years have seen a dramatic rise in mobi...  \n",
       "13153  The Information Technology (IT) workforce is c...  \n",
       "\n",
       "[13154 rows x 9 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstracts = pd.DataFrame()\n",
    "df = pd.DataFrame()\n",
    "i=0\n",
    "list_keywords=[]\n",
    "\n",
    "for file in files:\n",
    "    file_path=path+file\n",
    "    #print('Processing....'+file_path)\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    abstract = {}\n",
    "    \n",
    "    abstract['id'] = root.find('Award').find('AwardID').text\n",
    "    abstract['title'] = root.find('Award').find('AwardTitle').text\n",
    "    abstract['date'] = root.find('Award').find('AwardEffectiveDate').text\n",
    "    abstract['area'] = root.find('Award').find('Organization').find('Directorate').find('LongName').text\n",
    "    abstract['division'] = root.find('Award').find('Organization').find('Division').find('LongName').text\n",
    "    abstract['university'] = root.find('Award').find('Institution').find('Name').text\n",
    "    abstract['city'] = root.find('Award').find('Institution').find('CityName').text\n",
    "    abstract['country'] = root.find('Award').find('Institution').find('CountryName').text\n",
    "    abstract['abstract'] = root.find('Award').find('AbstractNarration').text\n",
    "    \n",
    "    df  = pd.DataFrame(abstract,index=[i])\n",
    "    i=i+1\n",
    "    \n",
    "    df_abstracts = pd.concat([df_abstracts, df])\n",
    "\n",
    "df_abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first iteration I tried the entire below pipeline but adding to the abstract the fields: *title*, *area*, *division*, *university*, *city* and *country* because I wanted to try if this metadata could add any value to the topics and to better cluster them, **but** it didn't work as expected so, for the final solution I decided to just use the *abstract* field and the results were better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:05:35.789025Z",
     "start_time": "2021-10-11T02:05:35.553791Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>area</th>\n",
       "      <th>division</th>\n",
       "      <th>university</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000005</td>\n",
       "      <td>collaborative research: excellence in research...</td>\n",
       "      <td>07/01/2020</td>\n",
       "      <td>direct for biological sciences</td>\n",
       "      <td>division of integrative organismal systems</td>\n",
       "      <td>howard university</td>\n",
       "      <td>washington</td>\n",
       "      <td>united states</td>\n",
       "      <td>head and heart development are closely intertw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000009</td>\n",
       "      <td>workshop on replication of a community-engaged...</td>\n",
       "      <td>01/01/2020</td>\n",
       "      <td>direct for education and human resources</td>\n",
       "      <td>division of undergraduate education</td>\n",
       "      <td>university of notre dame</td>\n",
       "      <td>notre dame</td>\n",
       "      <td>united states</td>\n",
       "      <td>the national academy of engineering identified...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000012</td>\n",
       "      <td>brazos analysis seminar</td>\n",
       "      <td>02/01/2020</td>\n",
       "      <td>direct for mathematical &amp; physical scien</td>\n",
       "      <td>division of mathematical sciences</td>\n",
       "      <td>baylor university</td>\n",
       "      <td>waco</td>\n",
       "      <td>united states</td>\n",
       "      <td>this award provides three years of funding to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000021</td>\n",
       "      <td>collaborative research: ecr eie dcl: the devel...</td>\n",
       "      <td>09/01/2020</td>\n",
       "      <td>direct for education and human resources</td>\n",
       "      <td>division of human resource development</td>\n",
       "      <td>michigan state university</td>\n",
       "      <td>east lansing</td>\n",
       "      <td>united states</td>\n",
       "      <td>this collaborative research project, involving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000028</td>\n",
       "      <td>research initiation award: microwave synthesis...</td>\n",
       "      <td>05/01/2020</td>\n",
       "      <td>direct for education and human resources</td>\n",
       "      <td>division of human resource development</td>\n",
       "      <td>bowie state university</td>\n",
       "      <td>bowie</td>\n",
       "      <td>united states</td>\n",
       "      <td>research initiation awards provide support for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>2055767</td>\n",
       "      <td>national center for next generation manufacturing</td>\n",
       "      <td>07/01/2021</td>\n",
       "      <td>direct for education and human resources</td>\n",
       "      <td>division of undergraduate education</td>\n",
       "      <td>tunxis community-technical college</td>\n",
       "      <td>farmington</td>\n",
       "      <td>united states</td>\n",
       "      <td>recent studies have highlighted the nation's i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>2055771</td>\n",
       "      <td>nsf-bsf: dynamics and operator algebras beyond...</td>\n",
       "      <td>08/01/2021</td>\n",
       "      <td>direct for mathematical &amp; physical scien</td>\n",
       "      <td>division of mathematical sciences</td>\n",
       "      <td>university of oregon eugene</td>\n",
       "      <td>eugene</td>\n",
       "      <td>united states</td>\n",
       "      <td>this project links two mathematical fields, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>2055772</td>\n",
       "      <td>collaborative research: satc: core: medium: na...</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>direct for computer &amp; info scie &amp; enginr</td>\n",
       "      <td>division of computer and network systems</td>\n",
       "      <td>international computer science institute</td>\n",
       "      <td>berkeley</td>\n",
       "      <td>united states</td>\n",
       "      <td>recent years have seen a dramatic rise in mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>2055773</td>\n",
       "      <td>collaborative research: satc: core: medium: na...</td>\n",
       "      <td>03/01/2021</td>\n",
       "      <td>direct for computer &amp; info scie &amp; enginr</td>\n",
       "      <td>division of computer and network systems</td>\n",
       "      <td>st mary's university san antonio</td>\n",
       "      <td>san antonio</td>\n",
       "      <td>united states</td>\n",
       "      <td>recent years have seen a dramatic rise in mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13153</th>\n",
       "      <td>2055781</td>\n",
       "      <td>increasing the cloud system administration ser...</td>\n",
       "      <td>07/01/2021</td>\n",
       "      <td>direct for education and human resources</td>\n",
       "      <td>division of undergraduate education</td>\n",
       "      <td>college of southern nevada</td>\n",
       "      <td>las vegas</td>\n",
       "      <td>united states</td>\n",
       "      <td>the information technology (it) workforce is c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13154 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title        date  \\\n",
       "0      2000005  collaborative research: excellence in research...  07/01/2020   \n",
       "1      2000009  workshop on replication of a community-engaged...  01/01/2020   \n",
       "2      2000012                            brazos analysis seminar  02/01/2020   \n",
       "3      2000021  collaborative research: ecr eie dcl: the devel...  09/01/2020   \n",
       "4      2000028  research initiation award: microwave synthesis...  05/01/2020   \n",
       "...        ...                                                ...         ...   \n",
       "13149  2055767  national center for next generation manufacturing  07/01/2021   \n",
       "13150  2055771  nsf-bsf: dynamics and operator algebras beyond...  08/01/2021   \n",
       "13151  2055772  collaborative research: satc: core: medium: na...  03/01/2021   \n",
       "13152  2055773  collaborative research: satc: core: medium: na...  03/01/2021   \n",
       "13153  2055781  increasing the cloud system administration ser...  07/01/2021   \n",
       "\n",
       "                                           area  \\\n",
       "0                direct for biological sciences   \n",
       "1      direct for education and human resources   \n",
       "2      direct for mathematical & physical scien   \n",
       "3      direct for education and human resources   \n",
       "4      direct for education and human resources   \n",
       "...                                         ...   \n",
       "13149  direct for education and human resources   \n",
       "13150  direct for mathematical & physical scien   \n",
       "13151  direct for computer & info scie & enginr   \n",
       "13152  direct for computer & info scie & enginr   \n",
       "13153  direct for education and human resources   \n",
       "\n",
       "                                         division  \\\n",
       "0      division of integrative organismal systems   \n",
       "1             division of undergraduate education   \n",
       "2               division of mathematical sciences   \n",
       "3          division of human resource development   \n",
       "4          division of human resource development   \n",
       "...                                           ...   \n",
       "13149         division of undergraduate education   \n",
       "13150           division of mathematical sciences   \n",
       "13151    division of computer and network systems   \n",
       "13152    division of computer and network systems   \n",
       "13153         division of undergraduate education   \n",
       "\n",
       "                                     university          city        country  \\\n",
       "0                             howard university    washington  united states   \n",
       "1                      university of notre dame    notre dame  united states   \n",
       "2                             baylor university          waco  united states   \n",
       "3                     michigan state university  east lansing  united states   \n",
       "4                        bowie state university         bowie  united states   \n",
       "...                                         ...           ...            ...   \n",
       "13149        tunxis community-technical college    farmington  united states   \n",
       "13150               university of oregon eugene        eugene  united states   \n",
       "13151  international computer science institute      berkeley  united states   \n",
       "13152          st mary's university san antonio   san antonio  united states   \n",
       "13153                college of southern nevada     las vegas  united states   \n",
       "\n",
       "                                                abstract  \n",
       "0      head and heart development are closely intertw...  \n",
       "1      the national academy of engineering identified...  \n",
       "2      this award provides three years of funding to ...  \n",
       "3      this collaborative research project, involving...  \n",
       "4      research initiation awards provide support for...  \n",
       "...                                                  ...  \n",
       "13149  recent studies have highlighted the nation's i...  \n",
       "13150  this project links two mathematical fields, dy...  \n",
       "13151  recent years have seen a dramatic rise in mobi...  \n",
       "13152  recent years have seen a dramatic rise in mobi...  \n",
       "13153  the information technology (it) workforce is c...  \n",
       "\n",
       "[13154 rows x 9 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df_abstracts.columns:\n",
    "    df_abstracts[col] = df_abstracts[col].str.lower()\n",
    "df_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:05:36.705677Z",
     "start_time": "2021-10-11T02:05:35.791021Z"
    }
   },
   "outputs": [],
   "source": [
    "df_abstracts.to_csv('./df_abstracts.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:05:36.750546Z",
     "start_time": "2021-10-11T02:05:36.708546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000005</td>\n",
       "      <td>head and heart development are closely intertw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000009</td>\n",
       "      <td>the national academy of engineering identified...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000012</td>\n",
       "      <td>this award provides three years of funding to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000021</td>\n",
       "      <td>this collaborative research project, involving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000028</td>\n",
       "      <td>research initiation awards provide support for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  2000005  head and heart development are closely intertw...\n",
       "1  2000009  the national academy of engineering identified...\n",
       "2  2000012  this award provides three years of funding to ...\n",
       "3  2000021  this collaborative research project, involving...\n",
       "4  2000028  research initiation awards provide support for..."
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enriched = pd.DataFrame()\n",
    "df_enriched['id'] = df_abstracts['id']\n",
    "df_enriched['text'] = df_abstracts['abstract']\n",
    "df_enriched.dropna(inplace=True)\n",
    "df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T02:05:36.780660Z",
     "start_time": "2021-10-11T02:05:36.757543Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_process_txt(txt:str):\n",
    "    \"\"\"Cleans the text string, removing HTML tags, non alpha-numeric characters and stopwords\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    txt : str\n",
    "        String to clean\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    txt : str\n",
    "        Clean string\n",
    "    \"\"\"\n",
    "\n",
    "    text = txt.replace('<.*?>',' ')\n",
    "    text = text.replace('[^\\w\\s]','')\n",
    "    text = text.translate(str.maketrans('','', string.punctuation))\n",
    "    text = \" \".join(word for word in text.split() if word not in en_stop_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize_pipe(doc):\n",
    "    \"\"\"Applys lemmatization to the document\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        Document to lemmatize\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Lemmatized document\n",
    "    \"\"\"\n",
    "    lemma_list = [str(tok.lemma_) for tok in doc] \n",
    "    return \" \".join(lemma_list)\n",
    "\n",
    "def preprocess_pipe(texts):\n",
    "    \"\"\"Helper to use spacy pipe fast processing to lemmatize text\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : pd.Series\n",
    "        String column to lemmatize\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    preproc_pipe : array\n",
    "        Lemmatized column\n",
    "    \"\"\"\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=20):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "    \n",
    "    return preproc_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to lemmatize the abstracts in order to get the root of every word and make easy the topic extraction and also because is a common good practice in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:16:33.481908Z",
     "start_time": "2021-10-11T02:05:36.783540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean it... Lemmatizing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lemmatize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000005</td>\n",
       "      <td>head heart development closely intertwined emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000009</td>\n",
       "      <td>national academy engineering identified solvin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000012</td>\n",
       "      <td>award provides years funding help defray expen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000021</td>\n",
       "      <td>collaborative research project involving michi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000028</td>\n",
       "      <td>research initiation awards provide support jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>2055767</td>\n",
       "      <td>recent studies highlighted nations increasing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>2055771</td>\n",
       "      <td>project links mathematical fields dynamics ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>2055772</td>\n",
       "      <td>recent years seen dramatic rise mobile apps he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>2055773</td>\n",
       "      <td>recent years seen dramatic rise mobile apps he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13153</th>\n",
       "      <td>2055781</td>\n",
       "      <td>information technology workforce chronically u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13084 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                          lemmatize\n",
       "0      2000005  head heart development closely intertwined emb...\n",
       "1      2000009  national academy engineering identified solvin...\n",
       "2      2000012  award provides years funding help defray expen...\n",
       "3      2000021  collaborative research project involving michi...\n",
       "4      2000028  research initiation awards provide support jun...\n",
       "...        ...                                                ...\n",
       "13149  2055767  recent studies highlighted nations increasing ...\n",
       "13150  2055771  project links mathematical fields dynamics ope...\n",
       "13151  2055772  recent years seen dramatic rise mobile apps he...\n",
       "13152  2055773  recent years seen dramatic rise mobile apps he...\n",
       "13153  2055781  information technology workforce chronically u...\n",
       "\n",
       "[13084 rows x 2 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enriched['clean'] = df_enriched.apply(lambda row : pre_process_txt(row['text']), axis=1)\n",
    "print('Clean it... Lemmatizing...')\n",
    "df_enriched['lemmatize'] = preprocess_pipe(df_enriched['clean'])\n",
    "df_enriched.drop(columns=['text','clean'],inplace=True)\n",
    "df_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:16:34.278026Z",
     "start_time": "2021-10-11T05:16:33.484911Z"
    }
   },
   "outputs": [],
   "source": [
    "df_enriched.to_csv('./df_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning a bit of memory, because text dataframes tend to be very memory heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:16:34.727927Z",
     "start_time": "2021-10-11T05:16:34.279687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_abstracts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:16:34.757932Z",
     "start_time": "2021-10-11T05:16:34.729929Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_topics(text):\n",
    "    \"\"\"\n",
    "    Function that takes a text as an input, and finds the most important topic and \n",
    "    takes the 3 most relevant words of that topic, using LDA model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Lemmatized string to get topics from\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        String with the 3 most relevant words of the topic\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "        count_vectorizer = CountVectorizer(stop_words='english')\n",
    "        count_data = count_vectorizer.fit_transform([text])\n",
    "        \n",
    "        number_topics = 1\n",
    "        number_words = 3\n",
    "        \n",
    "        # Create and fit the LDA model\n",
    "        lda = LDA(n_components=number_topics, n_jobs=-1)\n",
    "        lda.fit(count_data)\n",
    "\n",
    "        words = count_vectorizer.get_feature_names()\n",
    "\n",
    "        #Get topics from model. They are represented as a list e.g. ['military','army']\n",
    "        topics = [[words[i] for i in topic.argsort()[:-number_words - 1:-1]] for (topic_idx, topic) in enumerate(lda.components_)]\n",
    "        topics = np.array(topics).ravel()\n",
    "  \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (text)\n",
    "\n",
    "    return \" \".join(set(topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the before mentioned first iteration I found that in the topics were some words specific to the investigation field that didn't add much value to the topic analysis and were just adding noice to them, so I decided to eliminated them after doing a frequency analysis of the topics extracted in that first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:16:34.772929Z",
     "start_time": "2021-10-11T05:16:34.759929Z"
    }
   },
   "outputs": [],
   "source": [
    "bs_stop_words = [\"research\",\"project\",\"students\",\"data\",\"new\",\"university\",\"award\",\"states\",\"united\",\"nsfs\",\"study\",\"undergraduate\",\"'s\",\"1\",\"2\",\"state\"]\n",
    "\n",
    "def remove_bs_sw(txt):\n",
    "    \"\"\"\n",
    "    Remove business specific stop words\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Lemmatized string to delete common problem specific words that just adds noice to the topics\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Cleaned string\n",
    "    \"\"\"\n",
    "\n",
    "    text = \" \".join(word for word in txt.split() if word not in bs_stop_words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:22:55.343877Z",
     "start_time": "2021-10-11T05:16:34.774933Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000005</td>\n",
       "      <td>head heart development closely intertwined emb...</td>\n",
       "      <td>development cells neural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000009</td>\n",
       "      <td>national academy engineering identified solvin...</td>\n",
       "      <td>education ecosystem community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000012</td>\n",
       "      <td>provides years funding help defray expenses pa...</td>\n",
       "      <td>theory analysis texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000021</td>\n",
       "      <td>collaborative involving michigan north texas m...</td>\n",
       "      <td>stem faculty women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000028</td>\n",
       "      <td>initiation awards provide support junior midca...</td>\n",
       "      <td>vcp binders proteins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          lemmatize  \\\n",
       "0  2000005  head heart development closely intertwined emb...   \n",
       "1  2000009  national academy engineering identified solvin...   \n",
       "2  2000012  provides years funding help defray expenses pa...   \n",
       "3  2000021  collaborative involving michigan north texas m...   \n",
       "4  2000028  initiation awards provide support junior midca...   \n",
       "\n",
       "                          topics  \n",
       "0       development cells neural  \n",
       "1  education ecosystem community  \n",
       "2          theory analysis texas  \n",
       "3             stem faculty women  \n",
       "4           vcp binders proteins  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enriched['lemmatize'] = df_enriched.apply(lambda row : remove_bs_sw(row['lemmatize']), axis=1)\n",
    "df_enriched['topics'] = df_enriched['lemmatize'].apply(find_topics).values\n",
    "df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:22:55.973928Z",
     "start_time": "2021-10-11T05:22:55.345879Z"
    }
   },
   "outputs": [],
   "source": [
    "df_enriched.to_csv('./df_topics.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:23:00.183693Z",
     "start_time": "2021-10-11T05:22:55.976934Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp_sts = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Now after all the NLP data cleaning, I transformed the topics into word vectors to then use them in a clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:23:05.890667Z",
     "start_time": "2021-10-11T05:23:00.190690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03734  ,  0.0010196,  0.1125   , ..., -0.24715  , -0.40202  ,\n",
       "         0.49479  ],\n",
       "       [-0.55419  , -0.02895  , -0.39624  , ...,  0.28711  , -0.11356  ,\n",
       "         0.27036  ],\n",
       "       [ 0.10273  ,  0.0059362, -0.019216 , ...,  0.52837  , -0.34998  ,\n",
       "         0.45391  ],\n",
       "       ...,\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         0.       ],\n",
       "       [-0.043278 ,  0.028749 , -0.33234  , ..., -0.11468  , -0.13788  ,\n",
       "         0.011818 ]], dtype=float32)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df_enriched['topics'].str.cat(sep=' ')\n",
    "words = corpus.split()\n",
    "corpus = \" \".join(sorted(set(words), key=words.index))\n",
    "\n",
    "#Apply the model\n",
    "tokens = nlp_sts(corpus)\n",
    "\n",
    "#Convert tags into vectors for clustering model\n",
    "word_vectors = []\n",
    "for i in tokens:\n",
    "    word_vectors.append(i.vector)\n",
    "word_vectors = np.array(word_vectors)\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use DBSCAN since in the past got great results in other task and I found out that this algorithm has some good results in text clustering. The *eps* and *min_samples* were chosen after a short hyperparameter tunning were the goal was to reduce the amount of words in the *outlier* cluster (-1 label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:23:07.229436Z",
     "start_time": "2021-10-11T05:23:05.893666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
       "       dtype=int64),\n",
       " array([4760, 2347,   95,   13,   11,    4,    5,    5,    3,    7,    8,\n",
       "           8,    3,    7,    7], dtype=int64))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = DBSCAN(metric='cosine', eps=0.4, min_samples=7).fit_predict(word_vectors)\n",
    "np.unique(labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:23:07.334234Z",
     "start_time": "2021-10-11T05:23:07.232473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cells</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neural</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ecosystem</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7278</th>\n",
       "      <td>wuschel</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7279</th>\n",
       "      <td>imperial</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7280</th>\n",
       "      <td>electrocatalysts</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>calgebras</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>ld</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                topics  label\n",
       "0          development      0\n",
       "1                cells      0\n",
       "2               neural      0\n",
       "3            education      0\n",
       "4            ecosystem      0\n",
       "...                ...    ...\n",
       "7278           wuschel     -1\n",
       "7279          imperial     -1\n",
       "7280  electrocatalysts     -1\n",
       "7281         calgebras     -1\n",
       "7282                ld     -1\n",
       "\n",
       "[7283 rows x 2 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics = pd.DataFrame()\n",
    "df_topics['topics'] = corpus.split()\n",
    "df_topics['label'] = labels\n",
    "df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:23:07.349235Z",
     "start_time": "2021-10-11T05:23:07.336235Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_topic_labels(txt):\n",
    "    \n",
    "    \"\"\"\n",
    "    Assigns the labels of the topics to each document\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        String with the topics of the document\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        String with the clustering labels corresponding to the document\n",
    "    \"\"\"\n",
    "    \n",
    "    labels = []\n",
    "    \n",
    "    topics = txt.split()\n",
    "    \n",
    "    for t in topics:\n",
    "        l = df_topics[df_topics['topics']==t]['label'].values[0]\n",
    "        if l != -1:\n",
    "            labels.append(l)\n",
    "            \n",
    "    return \" \".join(str(x) for x in set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-11T05:23:38.443658Z",
     "start_time": "2021-10-11T05:23:07.351233Z"
    }
   },
   "outputs": [],
   "source": [
    "df_enriched['labels'] = df_enriched.apply(lambda row : assign_topic_labels(row['topics']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T01:40:52.405115Z",
     "start_time": "2021-10-12T01:40:52.315377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11932"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(df_enriched['labels'][df_enriched['labels'].str.len()==0]))\n",
    "display(len(df_enriched['labels'][df_enriched['labels'].str.len()==1]))\n",
    "display(len(df_enriched['labels'][df_enriched['labels'].str.len()==2]))\n",
    "display(len(df_enriched['labels'][df_enriched['labels'].str.len()==3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T00:39:58.156064Z",
     "start_time": "2021-10-12T00:39:58.137107Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_labels(txt):\n",
    "    \"\"\"\n",
    "    Cleans labels removing the '0' label if the document has more labels, \n",
    "    since it seems to be common among all the documents\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        String with the labels of a document\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Filtered labels\n",
    "    \"\"\"\n",
    "    \n",
    "    clean_labels = []\n",
    "    labels = txt.split()\n",
    "    \n",
    "    if len(labels) > 1:\n",
    "        clean_labels = [l for l in labels if l != '0']\n",
    "    else:\n",
    "        clean_labels = labels\n",
    "        \n",
    "    return \" \".join(clean_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T00:59:33.242631Z",
     "start_time": "2021-10-12T00:59:32.201624Z"
    }
   },
   "outputs": [],
   "source": [
    "df_enriched['labels'] = df_enriched.apply(lambda row : clean_labels(row['labels']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T01:40:04.045219Z",
     "start_time": "2021-10-12T01:40:04.017104Z"
    }
   },
   "source": [
    "Split the labels in different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:25:46.651272Z",
     "start_time": "2021-10-12T04:25:46.542092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>topics</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000005</td>\n",
       "      <td>head heart development closely intertwined emb...</td>\n",
       "      <td>development cells neural</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000009</td>\n",
       "      <td>national academy engineering identified solvin...</td>\n",
       "      <td>education ecosystem community</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000012</td>\n",
       "      <td>provides years funding help defray expenses pa...</td>\n",
       "      <td>theory analysis texas</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000021</td>\n",
       "      <td>collaborative involving michigan north texas m...</td>\n",
       "      <td>stem faculty women</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000028</td>\n",
       "      <td>initiation awards provide support junior midca...</td>\n",
       "      <td>vcp binders proteins</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13149</th>\n",
       "      <td>2055767</td>\n",
       "      <td>recent studies highlighted nations increasing ...</td>\n",
       "      <td>generation center manufacturing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13150</th>\n",
       "      <td>2055771</td>\n",
       "      <td>links mathematical fields dynamics operator al...</td>\n",
       "      <td>operator dynamical algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>2055772</td>\n",
       "      <td>recent years seen dramatic rise mobile apps he...</td>\n",
       "      <td>privacy health apps</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13152</th>\n",
       "      <td>2055773</td>\n",
       "      <td>recent years seen dramatic rise mobile apps he...</td>\n",
       "      <td>privacy health apps</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13153</th>\n",
       "      <td>2055781</td>\n",
       "      <td>information technology workforce chronically u...</td>\n",
       "      <td>systems cloud program</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13084 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                          lemmatize  \\\n",
       "0      2000005  head heart development closely intertwined emb...   \n",
       "1      2000009  national academy engineering identified solvin...   \n",
       "2      2000012  provides years funding help defray expenses pa...   \n",
       "3      2000021  collaborative involving michigan north texas m...   \n",
       "4      2000028  initiation awards provide support junior midca...   \n",
       "...        ...                                                ...   \n",
       "13149  2055767  recent studies highlighted nations increasing ...   \n",
       "13150  2055771  links mathematical fields dynamics operator al...   \n",
       "13151  2055772  recent years seen dramatic rise mobile apps he...   \n",
       "13152  2055773  recent years seen dramatic rise mobile apps he...   \n",
       "13153  2055781  information technology workforce chronically u...   \n",
       "\n",
       "                                topics labels label_1 label_2  \n",
       "0             development cells neural      0       0    None  \n",
       "1        education ecosystem community      0       0    None  \n",
       "2                theory analysis texas      1       1    None  \n",
       "3                   stem faculty women      0       0    None  \n",
       "4                 vcp binders proteins      0       0    None  \n",
       "...                                ...    ...     ...     ...  \n",
       "13149  generation center manufacturing      0       0    None  \n",
       "13150       operator dynamical algebra      0       0    None  \n",
       "13151              privacy health apps      0       0    None  \n",
       "13152              privacy health apps      0       0    None  \n",
       "13153            systems cloud program      0       0    None  \n",
       "\n",
       "[13084 rows x 6 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_labels = df_enriched['labels'].str.split(\" \",expand=True)\n",
    "df_enriched['label_1'] = split_labels[0]\n",
    "df_enriched['label_2'] = split_labels[1]\n",
    "df_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a random sample it's clear that the clustering has a good sense of topics with this 3 documents, because all of them talk about cutting edge technologies used to solve a specific problem in different fields of study.\n",
    "\n",
    "But, there's a lot of room to improvement, with more time to analyze the documents, the pre process could implement a way to analyze the acronyms that hide a lot of value about the main topic of the documents, also the model to generate the word vectors could be train specifically for the documents that we're processing in order to have a domain specific model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:43:28.920873Z",
     "start_time": "2021-10-12T04:43:28.875825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lemmatize</th>\n",
       "      <th>topics</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2003109</td>\n",
       "      <td>support chemical measurement imaging program d...</td>\n",
       "      <td>nmr mri warren</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>2013562</td>\n",
       "      <td>quantum computing quantum computers type compu...</td>\n",
       "      <td>davis quantum computer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585</th>\n",
       "      <td>2053096</td>\n",
       "      <td>denser liquid sink lighter vinegar sinks oil s...</td>\n",
       "      <td>water amoc atlantic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                          lemmatize  \\\n",
       "930    2003109  support chemical measurement imaging program d...   \n",
       "3367   2013562  quantum computing quantum computers type compu...   \n",
       "12585  2053096  denser liquid sink lighter vinegar sinks oil s...   \n",
       "\n",
       "                       topics labels label_1 label_2  \n",
       "930            nmr mri warren      1       1    None  \n",
       "3367   davis quantum computer      1       1    None  \n",
       "12585     water amoc atlantic      1       1    None  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enriched[df_enriched['label_1']=='1'].sample(3,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:44:30.085295Z",
     "start_time": "2021-10-12T04:44:27.995432Z"
    }
   },
   "outputs": [],
   "source": [
    "df_abstracts = pd.read_csv('./df_abstracts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T04:46:37.807818Z",
     "start_time": "2021-10-12T04:46:37.776819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['with support from the chemical measurement and imaging program in the division of chemistry, and co-funding from the atomic, molecular, and optical experimental physics program in the division of physics, professor warren warren and his group at duke university are working to expand the utility and accessibility of “hyperpolarized” nuclear magnetic resonance (nmr) spectroscopy. nmr is a powerful tool for chemists; it is useful for determining molecular structure and for monitoring the progress of chemical reactions. nmr\\'s clinical cousin, magnetic resonance imaging (mri) is an important tool for producing images of soft tissues in the body. however, both methods usually suffer from low sensitivity - meaning that they cannot detect small amounts of sample or low concentrations. \"hyperpolarization\" methods can increase nmr signals by a factor of 1000 or more, but are usually technically challenging and extremely expensive. the warren group is exploring the fundamental chemistry and physics behind new strategies with prospects of providing routine hyperpolarization as a simple and cost-effective add-on to any nmr spectrometer.  the team is also providing research and training opportunities in these critical technologies for members of underrepresented groups, and providing substantial k-12 science outreach.<br/><br/>the warren group studies the production, quantum statistical mechanics, and characterization of hyperpolarized, long-lived nuclear spin states in nmr and mri.  they seek to drastically improve the generality, fractional polarization, and absolute polarization levels of nuclei such as 15n, 13c and 19f from parahydrogen gas (p-h2) in solution, without chemical reaction, thereby enabling applications ranging from quantifying rotational-state effects on reactivity in solution to dark matter detection.  the ability to make and store large quantities of p-h2 should enable creation of massively large (kg size) continuously hyperpolarized targets which can serve as ultrasensitive magnetometers (e.g. for dark matter detection) or can drastically reduce the size of the magnets needed for clinical mri. applicability can also be expanded by the ability to make p-h2 at the l-atm/hour level using a simple, inexpensive laboratory apparatus. while ultra-low-field nmr is not new, this work aims to bring it into the mainstream, while also enabling better high-field experiments.  the aim is to reduce or eliminate the cost and complexity barriers to implementation of hyperpolarization.<br/><br/>this award reflects nsf\\'s statutory mission and has been deemed worthy of support through evaluation using the foundation\\'s intellectual merit and broader impacts review criteria.',\n",
       "       \"quantum computing is the study of quantum computers, which are a new type of computer that can process information using the laws of quantum mechanics.  once serious quantum computers can be built, they will be able to run new algorithms for selected problems that are faster than anything possible with classical computers - in some cases, exponentially faster. they will represent a new chapter in the computer and information revolution, the quantum chapter.  since the unexpected discovery of quantum computing in the 1980s and 1990s, research has made steady and exciting progress.  this award will help the university of california, davis join the growing and extremely important wave of research in quantum computing, by funding a new faculty position in the department of computer science. the new position will complement existing research strength in quantum computing and quantum information (qcqi) at uc davis in the departments of electrical and computer engineering, mathematics, and physics.  it will help uc davis reach a critical mass to sustain and expand quantum computing research and training indefinitely into the future.<br/><br/>the project will begin with a flexible search across all research areas and topics within qcqi that are suitable for a computer science department. these topics include: mathematically rigorous quantum algorithms, quantum complexity theory, heuristic quantum algorithms, quantum error correction, quantum communication, quantum software, quantum communication, quantum information bounds, quantum circuit optimization, design of quantum devices, and post-quantum cryptography.  the ideal candidate would interact with both non-quantum researchers in computer science and quantum researchers in other departments at uc davis.  as uc davis achieves a critical mass of qcqi faculty, existing topics courses will expand into cohesive graduate training.  existing topical seminars will expand into an interdepartmental qcqi research network at uc davis, and quantum computing related topics will begin to tunnel down into our undergraduate curriculum in order to ensure we have a sufficiently trained workforce in the future.<br/><br/>this award reflects nsf's statutory mission and has been deemed worthy of support through evaluation using the foundation's intellectual merit and broader impacts review criteria.\",\n",
       "       \"a denser liquid will sink below a lighter one just as vinegar sinks below oil in a salad dressing.  this sinking effect happens in the north atlantic around greenland and iceland, where warm surface water brought by the gulf stream cools in the subarctic climate and becomes denser than the water below it.  the cold surface water sinks to great depth where it flows slowly southward, circulating throughout the world's oceans before resurfacing and returning to the north atlantic. the resulting atlantic meridional overturning circulation (amoc) moves surface water northward and deep water southward throughout the entire atlantic basin.  the amoc transports heat northward over its whole length, not just from the warmer tropics to the colder high latitudes of the northern hemisphere but across the equator as well, transferring heat from the southern hemisphere into the northern hemisphere.<br/><br/>simulations of the response of climate to increases in greenhouse gas concentrations consistently show a slowdown of the amoc as climate warms, a consequence of warming-induced reductions in the density of surface water in the northern north atlantic.  density reduction is a direct consequence of warmer water temperature but reductions in saltiness also contribute, as fresh water (which is less dense) is added by melting ice sheets and increased precipitation. also, the increased moisture content of warmer surface air reduces evaporation, and reduced evaporation means less salty surface water since evaporation removes fresh water leaving salt behind.  there is observational evidence for amoc slowdown but the period of record is somewhat short for a definitive assessment.<br/><br/>several climatic effects of amoc slowdown have been claimed, including changes in precipitation over europe, an increase in north atlantic storms tracking into europe, changes in the frequency and strength of el nino events, and a southward shift in the intertropical convergence zone (itcz), the narrow rain band that typically sits north of the equator over the tropical oceans.  many authors have argued that the amoc slowdown is responsible for the north atlantic warming hole (nawh), a region of minimal warming or even slight cooling found in the north atlantic south of greenland in most climate change simulations.  a reduction in amoc heat transport into the northern north atlantic is a reasonable explanation for the warming hole, but it is possible to produce a nawh in global warming simulations using a model that does not allow amoc slowdown.<br/><br/>work supported through this award uses a novel methodology to examine the effects of amoc slowdown and their connection to the nawh using simulations from an ensemble of four climate models.  the simulations use a novel methodology in which just enough salt is removed from the surface ocean in the northern north atlantic to prevent the amoc slowdown that would otherwise occur due to greenhouse gas-induced warming.  a preliminary simulation performed with a version of the community earth system model (cesm) produces the nawh as a consequence of amoc slowdown, along with a reduction in rainfall over the warming hole and several other climatic impacts. but results from a single model are not definitive given that differences in model formulation can lead to substantial differences in model behavior.  the project also includes a detailed examination of the mechanisms through which amoc slowdown causes local and remote responses.<br/><br/>the work has societal relevance due to the human impacts of climate change and the need to help decision makers confronting climate change.  the principal investigators conduct outreach activities at two museums, the museum of riverside and the peabody museum of natural history, including public lectures and symposia as well as teacher development workshops.  the project supports a graduate student and a postdoctoral fellow, thereby supporting workforce development in this research area.<br/><br/>this award reflects nsf's statutory mission and has been deemed worthy of support through evaluation using the foundation's intellectual merit and broader impacts review criteria.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstracts[df_abstracts['id'].isin([2003109,2013562,2053096])]['abstract'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
